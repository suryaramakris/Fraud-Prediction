{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca93e7f4",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "# <center><div class=\"alert alert-success\">Fraud detection in auto insurance claims</div></center>\n",
    "### <div class=\"alert alert-danger\">Problem Statement:</br> To predict the fraud in auto insurance claims based on the demographic, policy, claim, and vehilce related features provided in the datasets and also generate the top 20 patterns for fraud on target attribute.</div>\n",
    "<div class=\"alert alert-info\"> Data Provided: </br>\n",
    "    1) Demographics Data: These files consist of the demographic data of each customer</br>\n",
    "    2) Policy Information: These files consist of the customer auto insurance policy information,connected to the claim with the insurance company.</br>\n",
    "    3) Data of Claim: These files consist of the details about the insurance claim, that the customer applied.</br>\n",
    "    4) Data of Vehicle: These files consist of the details about the Vehicle. </br>\n",
    "    5) Fraud Data: This Train.csv table contains the Fraud information details, like CustomerID, ReportedFraud.</div>\n",
    "<div class=\"alert alert-warning\">Evaluation metrics: </br> Just classifing a given customer details into fraud and Not fraud and blocking a genuine transaction for long time would bring bad impact on customer experience rather I consider providing probability score for each class and based on that the if there is a higher probability of transaction being fraud we might send that details to insurance company to have more checks instead of checking every customer details. Also by having more business understanding probability score helps to vary the threshold for considering any customer details as Fraud and Genuine.</br> \n",
    "    \n",
    "    Further, as it is important for insurance company to not miss out on any Fraudulent cases, considering Precision, Recall, and F1-score as metric as it stress more on correctly classifying the case of TRUE POSITIVE will be more precise in this case.</br>\n",
    "    \n",
    "&#10148; Log-Loss</br>\n",
    "&#10148; Confusion Metrics</br>\n",
    "&#10148; F1-score / F1 statistic</br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5af6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix, f1_score, ConfusionMatrixDisplay, make_scorer\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d175c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28836, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>InsuredAge</th>\n",
       "      <th>InsuredZipCode</th>\n",
       "      <th>InsuredGender</th>\n",
       "      <th>InsuredEducationLevel</th>\n",
       "      <th>InsuredOccupation</th>\n",
       "      <th>InsuredHobbies</th>\n",
       "      <th>CapitalGains</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>InsurancePolicyNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>Witnesses</th>\n",
       "      <th>PoliceReport</th>\n",
       "      <th>AmountOfTotalClaim</th>\n",
       "      <th>AmountOfInjuryClaim</th>\n",
       "      <th>AmountOfPropertyClaim</th>\n",
       "      <th>AmountOfVehicleDamage</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>days</th>\n",
       "      <th>ReportedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cust10000</td>\n",
       "      <td>35</td>\n",
       "      <td>454776</td>\n",
       "      <td>MALE</td>\n",
       "      <td>JD</td>\n",
       "      <td>armed-forces</td>\n",
       "      <td>movies</td>\n",
       "      <td>56700</td>\n",
       "      <td>-48500</td>\n",
       "      <td>119121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NoReport</td>\n",
       "      <td>65501.0</td>\n",
       "      <td>13417</td>\n",
       "      <td>6071</td>\n",
       "      <td>46013</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cust10001</td>\n",
       "      <td>36</td>\n",
       "      <td>454776</td>\n",
       "      <td>MALE</td>\n",
       "      <td>JD</td>\n",
       "      <td>tech-support</td>\n",
       "      <td>cross-fit</td>\n",
       "      <td>70600</td>\n",
       "      <td>-48500</td>\n",
       "      <td>119122</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YES</td>\n",
       "      <td>61382.0</td>\n",
       "      <td>15560</td>\n",
       "      <td>5919</td>\n",
       "      <td>39903</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cust10002</td>\n",
       "      <td>33</td>\n",
       "      <td>603260</td>\n",
       "      <td>MALE</td>\n",
       "      <td>JD</td>\n",
       "      <td>armed-forces</td>\n",
       "      <td>polo</td>\n",
       "      <td>66400</td>\n",
       "      <td>-63700</td>\n",
       "      <td>119123</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>66755.0</td>\n",
       "      <td>11630</td>\n",
       "      <td>11630</td>\n",
       "      <td>43495</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cust10003</td>\n",
       "      <td>36</td>\n",
       "      <td>474848</td>\n",
       "      <td>MALE</td>\n",
       "      <td>JD</td>\n",
       "      <td>armed-forces</td>\n",
       "      <td>polo</td>\n",
       "      <td>47900</td>\n",
       "      <td>-73400</td>\n",
       "      <td>119124</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>66243.0</td>\n",
       "      <td>12003</td>\n",
       "      <td>12003</td>\n",
       "      <td>42237</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cust10004</td>\n",
       "      <td>29</td>\n",
       "      <td>457942</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>High School</td>\n",
       "      <td>exec-managerial</td>\n",
       "      <td>dancing</td>\n",
       "      <td>0</td>\n",
       "      <td>-41500</td>\n",
       "      <td>119125</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YES</td>\n",
       "      <td>53544.0</td>\n",
       "      <td>8829</td>\n",
       "      <td>7234</td>\n",
       "      <td>37481</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CustomerID  InsuredAge  InsuredZipCode InsuredGender InsuredEducationLevel  \\\n",
       "0  Cust10000          35          454776          MALE                    JD   \n",
       "1  Cust10001          36          454776          MALE                    JD   \n",
       "2  Cust10002          33          603260          MALE                    JD   \n",
       "3  Cust10003          36          474848          MALE                    JD   \n",
       "4  Cust10004          29          457942        FEMALE           High School   \n",
       "\n",
       "  InsuredOccupation InsuredHobbies  CapitalGains  CapitalLoss  \\\n",
       "0      armed-forces         movies         56700       -48500   \n",
       "1      tech-support      cross-fit         70600       -48500   \n",
       "2      armed-forces           polo         66400       -63700   \n",
       "3      armed-forces           polo         47900       -73400   \n",
       "4   exec-managerial        dancing             0       -41500   \n",
       "\n",
       "   InsurancePolicyNumber  ...  Witnesses PoliceReport AmountOfTotalClaim  \\\n",
       "0                 119121  ...        0.0     NoReport            65501.0   \n",
       "1                 119122  ...        1.0          YES            61382.0   \n",
       "2                 119123  ...        3.0           NO            66755.0   \n",
       "3                 119124  ...        3.0           NO            66243.0   \n",
       "4                 119125  ...        1.0          YES            53544.0   \n",
       "\n",
       "  AmountOfInjuryClaim  AmountOfPropertyClaim  AmountOfVehicleDamage  Year  \\\n",
       "0               13417                   6071                  46013  2015   \n",
       "1               15560                   5919                  39903  2015   \n",
       "2               11630                  11630                  43495  2015   \n",
       "3               12003                  12003                  42237  2015   \n",
       "4                8829                   7234                  37481  2015   \n",
       "\n",
       "  Month  days ReportedFraud  \n",
       "0     2     3             N  \n",
       "1     2     2             N  \n",
       "2     1    15             N  \n",
       "3     1    19             N  \n",
       "4     1     9             N  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_data.csv\")\n",
    "df.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee28983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa0310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12003ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InsuredAge</th>\n",
       "      <th>InsuredZipCode</th>\n",
       "      <th>CapitalGains</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>InsurancePolicyNumber</th>\n",
       "      <th>CustomerLoyaltyPeriod</th>\n",
       "      <th>Policy_Deductible</th>\n",
       "      <th>PolicyAnnualPremium</th>\n",
       "      <th>UmbrellaLimit</th>\n",
       "      <th>VehicleYOM</th>\n",
       "      <th>...</th>\n",
       "      <th>NumberOfVehicles</th>\n",
       "      <th>BodilyInjuries</th>\n",
       "      <th>Witnesses</th>\n",
       "      <th>AmountOfTotalClaim</th>\n",
       "      <th>AmountOfInjuryClaim</th>\n",
       "      <th>AmountOfPropertyClaim</th>\n",
       "      <th>AmountOfVehicleDamage</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>2.883600e+04</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.00000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.0</td>\n",
       "      <td>28836.000000</td>\n",
       "      <td>28836.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.815370</td>\n",
       "      <td>502436.579068</td>\n",
       "      <td>23066.569566</td>\n",
       "      <td>-24940.612429</td>\n",
       "      <td>129312.517097</td>\n",
       "      <td>203.067867</td>\n",
       "      <td>1114.282529</td>\n",
       "      <td>1261.725810</td>\n",
       "      <td>9.836680e+05</td>\n",
       "      <td>2005.093113</td>\n",
       "      <td>...</td>\n",
       "      <td>1.823207</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>1.48429</td>\n",
       "      <td>52319.038355</td>\n",
       "      <td>7337.118428</td>\n",
       "      <td>7283.870197</td>\n",
       "      <td>37687.129387</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.495110</td>\n",
       "      <td>15.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.996377</td>\n",
       "      <td>72250.868871</td>\n",
       "      <td>27637.813724</td>\n",
       "      <td>27913.209608</td>\n",
       "      <td>11114.060267</td>\n",
       "      <td>99.932951</td>\n",
       "      <td>546.632816</td>\n",
       "      <td>204.882653</td>\n",
       "      <td>1.969282e+06</td>\n",
       "      <td>5.309956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980099</td>\n",
       "      <td>0.784764</td>\n",
       "      <td>1.04469</td>\n",
       "      <td>25080.664083</td>\n",
       "      <td>4427.638593</td>\n",
       "      <td>4375.842738</td>\n",
       "      <td>17977.048232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516162</td>\n",
       "      <td>7.603878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>430104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-111100.000000</td>\n",
       "      <td>110122.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>436.280000</td>\n",
       "      <td>-1.000000e+06</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>448603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-50000.000000</td>\n",
       "      <td>119698.750000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>622.000000</td>\n",
       "      <td>1125.247500</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>44686.250000</td>\n",
       "      <td>4743.750000</td>\n",
       "      <td>4862.000000</td>\n",
       "      <td>32193.250000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>466691.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129278.500000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1266.440000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>58360.000000</td>\n",
       "      <td>7147.000000</td>\n",
       "      <td>7051.000000</td>\n",
       "      <td>42457.500000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>603848.000000</td>\n",
       "      <td>49000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138933.250000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>1396.605000</td>\n",
       "      <td>4.859610e+05</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>68961.750000</td>\n",
       "      <td>10571.250000</td>\n",
       "      <td>10327.000000</td>\n",
       "      <td>49535.750000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>620962.000000</td>\n",
       "      <td>100500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148619.000000</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2047.590000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>114920.000000</td>\n",
       "      <td>21450.000000</td>\n",
       "      <td>23670.000000</td>\n",
       "      <td>79560.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         InsuredAge  InsuredZipCode   CapitalGains    CapitalLoss  \\\n",
       "count  28836.000000    28836.000000   28836.000000   28836.000000   \n",
       "mean      38.815370   502436.579068   23066.569566  -24940.612429   \n",
       "std        7.996377    72250.868871   27637.813724   27913.209608   \n",
       "min       19.000000   430104.000000       0.000000 -111100.000000   \n",
       "25%       33.000000   448603.000000       0.000000  -50000.000000   \n",
       "50%       38.000000   466691.000000       0.000000       0.000000   \n",
       "75%       44.000000   603848.000000   49000.000000       0.000000   \n",
       "max       64.000000   620962.000000  100500.000000       0.000000   \n",
       "\n",
       "       InsurancePolicyNumber  CustomerLoyaltyPeriod  Policy_Deductible  \\\n",
       "count           28836.000000           28836.000000       28836.000000   \n",
       "mean           129312.517097             203.067867        1114.282529   \n",
       "std             11114.060267              99.932951         546.632816   \n",
       "min            110122.000000               1.000000         500.000000   \n",
       "25%            119698.750000             126.000000         622.000000   \n",
       "50%            129278.500000             199.000000        1000.000000   \n",
       "75%            138933.250000             267.000000        1627.000000   \n",
       "max            148619.000000             479.000000        2000.000000   \n",
       "\n",
       "       PolicyAnnualPremium  UmbrellaLimit    VehicleYOM  ...  \\\n",
       "count         28836.000000   2.883600e+04  28836.000000  ...   \n",
       "mean           1261.725810   9.836680e+05   2005.093113  ...   \n",
       "std             204.882653   1.969282e+06      5.309956  ...   \n",
       "min             436.280000  -1.000000e+06   1995.000000  ...   \n",
       "25%            1125.247500   0.000000e+00   2001.000000  ...   \n",
       "50%            1266.440000   0.000000e+00   2005.000000  ...   \n",
       "75%            1396.605000   4.859610e+05   2010.000000  ...   \n",
       "max            2047.590000   1.000000e+07   2015.000000  ...   \n",
       "\n",
       "       NumberOfVehicles  BodilyInjuries    Witnesses  AmountOfTotalClaim  \\\n",
       "count      28836.000000    28836.000000  28836.00000        28836.000000   \n",
       "mean           1.823207        0.985782      1.48429        52319.038355   \n",
       "std            0.980099        0.784764      1.04469        25080.664083   \n",
       "min            1.000000        0.000000     -1.00000          150.000000   \n",
       "25%            1.000000        0.000000      1.00000        44686.250000   \n",
       "50%            1.000000        1.000000      1.00000        58360.000000   \n",
       "75%            3.000000        2.000000      2.00000        68961.750000   \n",
       "max            4.000000        2.000000      3.00000       114920.000000   \n",
       "\n",
       "       AmountOfInjuryClaim  AmountOfPropertyClaim  AmountOfVehicleDamage  \\\n",
       "count         28836.000000           28836.000000           28836.000000   \n",
       "mean           7337.118428            7283.870197           37687.129387   \n",
       "std            4427.638593            4375.842738           17977.048232   \n",
       "min               0.000000               0.000000             109.000000   \n",
       "25%            4743.750000            4862.000000           32193.250000   \n",
       "50%            7147.000000            7051.000000           42457.500000   \n",
       "75%           10571.250000           10327.000000           49535.750000   \n",
       "max           21450.000000           23670.000000           79560.000000   \n",
       "\n",
       "          Year         Month          days  \n",
       "count  28836.0  28836.000000  28836.000000  \n",
       "mean    2015.0      1.495110     15.010300  \n",
       "std        0.0      0.516162      7.603878  \n",
       "min     2015.0      1.000000      1.000000  \n",
       "25%     2015.0      1.000000      9.000000  \n",
       "50%     2015.0      1.000000     15.000000  \n",
       "75%     2015.0      2.000000     21.000000  \n",
       "max     2015.0      3.000000     31.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0ea0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(data,col):\n",
    "    fig,(ax1,ax2)=plt.subplots(2,1)\n",
    "    sns.distplot(data[col],ax=ax1)\n",
    "    sns.boxplot(data[col],ax=ax2)\n",
    "plot(df,'CapitalGains')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b4cf440",
   "metadata": {},
   "source": [
    "# By observing the pdf and boxplot we can conclude the value in the CapitalGains feature is geniune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46923204",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d9a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year_PolicyCoverage\"] = df['DateOfPolicyCoverage'].apply(lambda x: int(x.split(\"-\")[0]))\n",
    "df[\"Month_PolicyCoverage\"] = df['DateOfPolicyCoverage'].apply(lambda x: int(x.split(\"-\")[1]))\n",
    "df[\"days_PolicyCoverage\"] = df['DateOfPolicyCoverage'].apply(lambda x: int(x.split(\"-\")[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b567b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the Policy CombinedSingleLimit into split-limit and combinedsinglelimit\n",
    "df['Policy_SplitLimit'] = df['Policy_CombinedSingleLimit'].apply(lambda x: int(x.split(\"/\")[0]))\n",
    "df['Policy_CombinedSingleLimit'] = df['Policy_CombinedSingleLimit'].apply(lambda x: int(x.split(\"/\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32822fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CustomerID', 'InsurancePolicyNumber','VehicleID','DateOfPolicyCoverage','InsuredEducationLevel','InsuredRelationship','IncidentAddress'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a85cf0a",
   "metadata": {},
   "source": [
    "## LabelEncoding -- ReportedFraud, VehicleModel\n",
    "\n",
    "## One-hot encoding -- InsuredGender, InsuredHobbies, InsuredOccupation, InsurancePolicyState, IncidentState, VehicleMake, TypeOfIncident, TypeOfCollission, SeverityOfIncident, AuthoritiesContacted, IncidentCity,  PropertyDamage, PoliceReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d14d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform labelEncoding on -- ReportedFraud, VehicleModel\n",
    "\n",
    "df['ReportedFraud'] = df['ReportedFraud'].astype(\"category\").cat.codes\n",
    "df['VehicleModel'] = df['VehicleModel'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495aab9d",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4e47744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing one-hot encoding\n",
    "OHE_cols = ['InsuredGender', 'InsuredHobbies', 'InsuredOccupation', 'InsurancePolicyState', 'IncidentState', 'VehicleMake',\n",
    "            'TypeOfIncident', 'TypeOfCollission', 'SeverityOfIncident', 'AuthoritiesContacted', 'IncidentCity',\n",
    "            'PropertyDamage', 'PoliceReport']\n",
    "\n",
    "for i in OHE_cols:\n",
    "    #Create object for one-hot encoding\n",
    "    encoder = ce.OneHotEncoder(cols=i, handle_unknown='value',return_df=True,use_cat_names=True)\n",
    "\n",
    "    #Fit and transform Data\n",
    "    data_encoded1 = encoder.fit_transform(df[i])\n",
    "    \n",
    "    #drop column in the original dataframe\n",
    "    df.drop(i,axis=1,inplace=True)\n",
    "    \n",
    "    #concat onehotencoded data to original\n",
    "    df = pd.concat([df, data_encoded1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6abf454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28836, 117)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InsuredAge</th>\n",
       "      <th>InsuredZipCode</th>\n",
       "      <th>CapitalGains</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>CustomerLoyaltyPeriod</th>\n",
       "      <th>Policy_CombinedSingleLimit</th>\n",
       "      <th>Policy_Deductible</th>\n",
       "      <th>PolicyAnnualPremium</th>\n",
       "      <th>UmbrellaLimit</th>\n",
       "      <th>VehicleYOM</th>\n",
       "      <th>...</th>\n",
       "      <th>IncidentCity_City6</th>\n",
       "      <th>IncidentCity_City4</th>\n",
       "      <th>IncidentCity_City3</th>\n",
       "      <th>IncidentCity_City2</th>\n",
       "      <th>IncidentCity_City7</th>\n",
       "      <th>PropertyDamage_YES</th>\n",
       "      <th>PropertyDamage_NO</th>\n",
       "      <th>PoliceReport_NoReport</th>\n",
       "      <th>PoliceReport_YES</th>\n",
       "      <th>PoliceReport_NO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>454776</td>\n",
       "      <td>56700</td>\n",
       "      <td>-48500</td>\n",
       "      <td>49</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1632.73</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>454776</td>\n",
       "      <td>70600</td>\n",
       "      <td>-48500</td>\n",
       "      <td>114</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1255.19</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>603260</td>\n",
       "      <td>66400</td>\n",
       "      <td>-63700</td>\n",
       "      <td>167</td>\n",
       "      <td>1000</td>\n",
       "      <td>617</td>\n",
       "      <td>1373.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>474848</td>\n",
       "      <td>47900</td>\n",
       "      <td>-73400</td>\n",
       "      <td>190</td>\n",
       "      <td>1000</td>\n",
       "      <td>722</td>\n",
       "      <td>1337.60</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>457942</td>\n",
       "      <td>0</td>\n",
       "      <td>-41500</td>\n",
       "      <td>115</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>1353.73</td>\n",
       "      <td>4279863</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   InsuredAge  InsuredZipCode  CapitalGains  CapitalLoss  \\\n",
       "0          35          454776         56700       -48500   \n",
       "1          36          454776         70600       -48500   \n",
       "2          33          603260         66400       -63700   \n",
       "3          36          474848         47900       -73400   \n",
       "4          29          457942             0       -41500   \n",
       "\n",
       "   CustomerLoyaltyPeriod  Policy_CombinedSingleLimit  Policy_Deductible  \\\n",
       "0                     49                         300               1000   \n",
       "1                    114                         300               1000   \n",
       "2                    167                        1000                617   \n",
       "3                    190                        1000                722   \n",
       "4                    115                         300                500   \n",
       "\n",
       "   PolicyAnnualPremium  UmbrellaLimit  VehicleYOM  ...  IncidentCity_City6  \\\n",
       "0              1632.73              0        2008  ...                   0   \n",
       "1              1255.19              0        2006  ...                   0   \n",
       "2              1373.38              0        1999  ...                   1   \n",
       "3              1337.60              0        2003  ...                   1   \n",
       "4              1353.73        4279863        2010  ...                   1   \n",
       "\n",
       "   IncidentCity_City4  IncidentCity_City3  IncidentCity_City2  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   IncidentCity_City7  PropertyDamage_YES  PropertyDamage_NO  \\\n",
       "0                   0                   1                  0   \n",
       "1                   0                   1                  0   \n",
       "2                   0                   1                  0   \n",
       "3                   0                   1                  0   \n",
       "4                   0                   0                  1   \n",
       "\n",
       "   PoliceReport_NoReport  PoliceReport_YES  PoliceReport_NO  \n",
       "0                      1                 0                0  \n",
       "1                      0                 1                0  \n",
       "2                      0                 0                1  \n",
       "3                      0                 0                1  \n",
       "4                      0                 1                0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be7aabfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207348e",
   "metadata": {},
   "source": [
    "## Split the data into train and test dataset to evaluate the model for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8ce8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('ReportedFraud',axis=1)\n",
    "y = df['ReportedFraud']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e954a9",
   "metadata": {},
   "source": [
    "# <center>Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8d73d",
   "metadata": {},
   "source": [
    "### Random model (benchmark model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84957348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets build a Random model (as our benchmark model)\n",
    "rnd = x_test.shape[0]\n",
    "rnd_probpred = []\n",
    "rnd_pred = []\n",
    "\n",
    "def random_model(rnd):\n",
    "    for i in range(rnd):\n",
    "        a = random.uniform(0,1)\n",
    "        rnd_probpred.append([a,1-a])\n",
    "\n",
    "random_model(rnd)\n",
    "rnd_probpred = np.asarray(rnd_probpred)\n",
    "\n",
    "for i in rnd_probpred:\n",
    "    rnd_pred.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd80d431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for the random model is:  [[3214 3159]\n",
      " [1146 1132]]\n",
      "The Log-Loss for a Random Model is:  0.9940075125707256\n",
      "The F1-Score for a Random Model is:  0.3446491094534937\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, rnd_pred)\n",
    "print(\"The confusion matrix for the random model is: \",confusion_matrix)\n",
    "\n",
    "print(\"The Log-Loss for a Random Model is: \",log_loss(y_test,rnd_probpred))\n",
    "\n",
    "print(\"The F1-Score for a Random Model is: \",f1_score(y_test,rnd_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840d8dc",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5c6ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=BernoulliNB(),\n",
       "             param_grid=[{'alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                    1000, 10000],\n",
       "                          'fit_prior': [True, False]}],\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying grid search to hyperparameter tune the BernoulliNB model\n",
    "\n",
    "#Instance for Naive Bayes classifier\n",
    "nb = BernoulliNB()\n",
    "\n",
    "#params for Bernoulli Naive bayes model\n",
    "nb_params = [{'alpha':[10**x for x in range(-5,5)], 'fit_prior':[True,False]}]\n",
    "\n",
    "#Instance for Naive Bayes Classifier and f1 metric\n",
    "f1score = make_scorer(f1_score,greater_is_better=True, needs_proba=False)\n",
    "nbclf = GridSearchCV(nb, nb_params, cv=10, scoring=f1score)\n",
    "\n",
    "#training the model to find the best parameter\n",
    "nbclf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3818b6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter after GridSearch comes out to be:  {'alpha': 1, 'fit_prior': True}\n",
      "With the F1 statistic of:  0.6626685857926666\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameter after GridSearch comes out to be: \",nbclf.best_params_)\n",
    "print(\"With the F1 statistic of: \",nbclf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc1d56",
   "metadata": {},
   "source": [
    "#### Well Naive bayes surely is doing good than a random model with so we can take this into consideration. Now trying out with more complex models and try improving the F1-score further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624fe80",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cc4f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max sclaer\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_trainknn = scaler.transform(x_train)\n",
    "x_testknn = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af1f07d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying grid search to hyperparameter tune the KNN model\n",
    "\n",
    "#Instance for KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Hyperparameter for search\n",
    "knn_params = [{'n_neighbors':list(range(1,20,2)), 'weights':['uniform','distance']}]\n",
    "\n",
    "#Instance for Grid Search CV\n",
    "f1score = make_scorer(f1_score, greater_is_better=True, needs_proba=False)\n",
    "clf = GridSearchCV(knn, knn_params, cv=10, scoring=f1score)\n",
    "\n",
    "#training the model to find the best parameter\n",
    "clf.fit(x_trainknn, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ec89a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter after GridSearch comes out to be:  {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "With the F1 statistic of:  0.8702983984872918\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameter after GridSearch comes out to be: \",clf.best_params_)\n",
    "print(\"With the F1 statistic of: \",clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850577f",
   "metadata": {},
   "source": [
    "#### Thats F1-score of 0.87 with KNN, so definitely KNN is performing good than a random model and working considerably well. Now trying out with more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb64cf",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c8cb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Instance for StandardScaler \n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_trainlr = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "291c9264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(n_jobs=-1),\n",
       "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'max_iter': [100, 150, 200],\n",
       "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyper-parameter tunning for logistic regression\n",
    "\n",
    "#Instance for the LogisticRegression\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "#params for search\n",
    "lr_params = [{'penalty':['l1','l2','elasticnet'],'C':[10**x for x in range(-3,3)],'max_iter':[100,150,200]}]\n",
    "\n",
    "#Instance for Grid Search CV\n",
    "f1score = make_scorer(f1_score, greater_is_better=True, needs_proba=False)\n",
    "lrclf = GridSearchCV(lr, lr_params, cv=10, scoring=f1score)\n",
    "\n",
    "#training the model to find the best parameter\n",
    "lrclf.fit(x_trainlr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1677e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter after GridSearch comes out to be:  {'C': 10, 'max_iter': 100, 'penalty': 'l2'}\n",
      "With the F1 statistic of:  0.6696432931568516\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameter after GridSearch comes out to be: \",lrclf.best_params_)\n",
    "print(\"With the F1 statistic of: \",lrclf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39bad5",
   "metadata": {},
   "source": [
    "#### From the F1-score of LogisticRegression definitely it is performing good than a random model and Naive Bayes Classifier but KNN beats Logistic Regression in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a8602",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4588c894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                          'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
       "                                        14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "                                        24, 25, 26, 27, 28, 29],\n",
       "                          'min_samples_split': [2, 3, 4, 5]}],\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyper-parameter tunning for DecisionTreeClassifier\n",
    "\n",
    "#Instance for the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "#params for search\n",
    "dt_params = [{'criterion':['gini','entropy','log_loss'],'max_depth':[x for x in range(2,30)],'min_samples_split':[2,3,4,5]}]\n",
    "\n",
    "#Instance for Grid Search CV\n",
    "f1score = make_scorer(f1_score, greater_is_better=True, needs_proba=False)\n",
    "dtclf = GridSearchCV(dt, dt_params, cv=10, scoring=f1score)\n",
    "\n",
    "#training the model to find the best parameter\n",
    "dtclf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df66765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter after GridSearch comes out to be:  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 2}\n",
      "With the F1 statistic of:  0.7411575027932199\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameter after GridSearch comes out to be: \",dtclf.best_params_)\n",
    "print(\"With the F1 statistic of: \",dtclf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e824f",
   "metadata": {},
   "source": [
    "#### From the F1-score we can conclude that decision tree classifier is working better than randomModel, Naive Bayes, Logistic Regression but KNN is the best performer till now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb8efd3",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303bae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(n_jobs=-1),\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'min_samples_split': [2, 3, 4],\n",
       "                          'n_estimators': [100, 150, 200, 250, 300, 350, 400,\n",
       "                                           450, 500, 550, 600, 650, 700, 750,\n",
       "                                           800, 850, 900, 950]}],\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyper-parameter tunning for RandomForestClassifier\n",
    "\n",
    "#Instance for the RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "#params for search\n",
    "rf_params = [{'criterion':['gini','entropy'],'n_estimators':[x for x in range(100,1000,50)],'min_samples_split':[2,3,4]}]\n",
    "\n",
    "#Instance for Grid Search CV\n",
    "f1score = make_scorer(f1_score, greater_is_better=True, needs_proba=False)\n",
    "rfclf = GridSearchCV(rf, rf_params, cv=10, scoring=f1score)\n",
    "\n",
    "#training the model to find the best parameter\n",
    "rfclf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c3a4217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter after GridSearch comes out to be:  {'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 600}\n",
      "With the F1 statistic of:  0.8475012117567303\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameter after GridSearch comes out to be: \",rfclf.best_params_)\n",
    "print(\"With the F1 statistic of: \",rfclf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36c99293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomModel</td>\n",
       "      <td>0.340100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.662669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.870298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.669643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.741158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest Classifier</td>\n",
       "      <td>0.847501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models  F1-Score\n",
       "0               RandomModel  0.340100\n",
       "1               Naive Bayes  0.662669\n",
       "2                       KNN  0.870298\n",
       "3      Logistic Regression   0.669643\n",
       "4  Decision Tree Classifier  0.741158\n",
       "5   RandomForest Classifier  0.847501"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for Model Score Comparison\n",
    "d = {\"Models\":['RandomModel','Naive Bayes', 'KNN','Logistic Regression ','Decision Tree Classifier','RandomForest Classifier'],\n",
    "     \"F1-Score\":[0.3401, nbclf.best_score_, clf.best_score_, lrclf.best_score_, dtclf.best_score_, rfclf.best_score_]}\n",
    "Mscore = pd.DataFrame(d,columns=['Models', 'F1-Score'])\n",
    "Mscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275a682",
   "metadata": {},
   "source": [
    "### Random Forest classifier is doing great and got near KNN, but still KNN tends to perform well that any other models\n",
    "## So i am using the KNN clasifier as my model to predict the unseen data. Since we have performed hyperparameter tuning it is for sure we are not over-fitting or under-fitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
